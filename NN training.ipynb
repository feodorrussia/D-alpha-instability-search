{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Program to prepare data & train NNs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:45:55.844217Z",
     "start_time": "2024-07-31T19:45:52.734521Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:39.826117Z",
     "start_time": "2024-07-31T20:28:39.805394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "interval_path = \"data/intervals/\"\n",
    "signal_path = \"data/d-alpha/\"\n",
    "F_ID = \"44184\"  # 44172 | 44184 | 44194 | 44350\n",
    "\n",
    "POINTS_DIM = 1024\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:40.060333Z",
     "start_time": "2024-07-31T20:28:40.032787Z"
    }
   },
   "outputs": [],
   "source": [
    "# interval_df = pd.read_csv(interval_path + f\"df/{F_ID}_data.csv\")\n",
    "# interval_df.t *= 1e3\n",
    "# interval_df.describe()\n",
    "\n",
    "# if os.path.isfile(interval_path + f\"df/{F_ID}_data.csv\"):\n",
    "#     df = pd.read_csv(interval_path + f\"df/{F_ID}_data.csv\", sep=\",\")\n",
    "# else:\n",
    "#     df = pd.read_csv(signal_path + f\"sht{F_ID}.txt\", sep=\",\")  # read_dataFile(interval_path + check_filename + \".txt\", check_F_ID)  # \"_exportGlobus2.dat\"\n",
    "#     df[\"ch1_marked\"] = 0\n",
    "#     df[\"ch1_ai_marked\"] = 0\n",
    "\n",
    "# df.loc[int(interval_df.t[0]): int(interval_df.t[interval_df.shape[0] - 1]), 'ch1_marked'] = interval_df.ch1_marked.to_numpy()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:40.611650Z",
     "start_time": "2024-07-31T20:28:40.553945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>ch1</th>\n",
       "      <th>ch1_marked</th>\n",
       "      <th>ch1_ai_marked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65970.000000</td>\n",
       "      <td>65970.000000</td>\n",
       "      <td>65970.000000</td>\n",
       "      <td>65970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>197.454500</td>\n",
       "      <td>0.552893</td>\n",
       "      <td>0.240518</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.044043</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.487387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>164.470000</td>\n",
       "      <td>0.191710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>180.962250</td>\n",
       "      <td>0.401320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>197.454500</td>\n",
       "      <td>0.534240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>213.946750</td>\n",
       "      <td>0.674820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>230.439000</td>\n",
       "      <td>1.536200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t           ch1    ch1_marked  ch1_ai_marked\n",
       "count  65970.000000  65970.000000  65970.000000        65970.0\n",
       "mean     197.454500      0.552893      0.240518            0.0\n",
       "std       19.044043      0.186984      0.487387            0.0\n",
       "min      164.470000      0.191710      0.000000            0.0\n",
       "25%      180.962250      0.401320      0.000000            0.0\n",
       "50%      197.454500      0.534240      0.000000            0.0\n",
       "75%      213.946750      0.674820      0.000000            0.0\n",
       "max      230.439000      1.536200      2.000000            0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(interval_path + f\"df/{F_ID}_data.csv\")  # _full\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:45.545403Z",
     "start_time": "2024-07-31T20:28:45.528393Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalise_series(data):\n",
    "    max_point, min_point, median_value = data.max(), data.min(), np.median(data)\n",
    "    return (data - median_value) / abs(max_point - min_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:46.256136Z",
     "start_time": "2024-07-31T20:28:46.134663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(509, 2, 1024)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "l_edge = 0\n",
    "slicing_set = [[df.shape[0], 128]]  # [[df.shape[0], 64]] | [[155000, int(POINTS_DIM * 1.5)], [240000, 128], [df.shape[0], int(POINTS_DIM * 1.5)]]\n",
    "# step = 100\n",
    "\n",
    "for r_edge, step in slicing_set:\n",
    "    while l_edge + POINTS_DIM < r_edge:\n",
    "        df_slice = df.iloc[l_edge:l_edge + POINTS_DIM]\n",
    "        data.append([normalise_series(df_slice.ch1.to_numpy()), df_slice.ch1_marked.to_numpy()])\n",
    "        l_edge += step\n",
    "    print(len(data))\n",
    "\n",
    "if l_edge + POINTS_DIM - slicing_set[-1][1] != slicing_set[-1][0] - 1:\n",
    "    # print(df.shape[0] - l_edge)\n",
    "    df_slice = df.iloc[df.shape[0] - POINTS_DIM:]\n",
    "    data.append([normalise_series(df_slice.ch1.to_numpy()), df_slice.ch1_marked.to_numpy()])\n",
    "\n",
    "data_array = np.array(data)\n",
    "\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:50.101297Z",
     "start_time": "2024-07-31T20:28:50.074112Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data_array[:, 0], data_array[:, 1], test_size=0.1, random_state=42)\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(data_array)\n",
    "X_train, y_train = data_array[:, 0], data_array[:, 1]\n",
    "# print(X_train[:10], y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, data_array[:, 0]), axis=0)\n",
    "y_train = np.concatenate((y_train, data_array[:, 1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:51.134791Z",
     "start_time": "2024-07-31T20:28:51.113269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 1024)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:48.990865Z",
     "start_time": "2024-07-31T20:28:48.966858Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:28:49.362082Z",
     "start_time": "2024-07-31T20:28:49.348399Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiclass.\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES + 1)[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for biclass.\n",
    "# y_train[y_train != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_multi_model(POINTS_DIM, NUM_CLASSES):\n",
    "    init_relu = tf.keras.initializers.HeUniform()\n",
    "\n",
    "    #Входной слой\n",
    "    inputs = tf.keras.layers.Input(shape=(POINTS_DIM, 1,))\n",
    "    conv_1 = tf.keras.layers.Conv1D(64, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(),\n",
    "                                    strides=2, padding='same', \n",
    "                                    kernel_initializer=init_relu,\n",
    "                                    use_bias=False)(inputs)\n",
    "    #Сворачиваем\n",
    "    conv_1_1 = tf.keras.layers.Conv1D(128, 4, \n",
    "                                      activation=tf.keras.layers.LeakyReLU(), \n",
    "                                      strides=2,\n",
    "                                      padding='same', \n",
    "                                      kernel_initializer=init_relu,\n",
    "                                      use_bias=False)(conv_1)\n",
    "    batch_norm_1 = tf.keras.layers.BatchNormalization()(conv_1_1)\n",
    "\n",
    "    #2\n",
    "    conv_2 = tf.keras.layers.Conv1D(256, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer=init_relu,\n",
    "                                    use_bias=False)(batch_norm_1)\n",
    "    batch_norm_2 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "\n",
    "    #3\n",
    "    conv_3 = tf.keras.layers.Conv1D(512, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer=init_relu,\n",
    "                                    use_bias=False)(batch_norm_2)\n",
    "    batch_norm_3 = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "\n",
    "    #4\n",
    "    conv_4 = tf.keras.layers.Conv1D(512, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer=init_relu,\n",
    "                                    use_bias=False)(batch_norm_3)\n",
    "    batch_norm_4 = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "\n",
    "    #Разворачиваем\n",
    "    #1\n",
    "    up_1 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(512, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer=init_relu,\n",
    "                                                                          use_bias=False)(conv_4), conv_3])\n",
    "    batch_up_1 = tf.keras.layers.BatchNormalization()(up_1)\n",
    "\n",
    "    #Добавим Dropout от переобучения\n",
    "    batch_up_1 = tf.keras.layers.Dropout(0.25)(batch_up_1, training=True)\n",
    "\n",
    "    #2\n",
    "    up_2 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(256, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer=init_relu,\n",
    "                                                                          use_bias=False)(batch_up_1), conv_2])\n",
    "    batch_up_2 = tf.keras.layers.BatchNormalization()(up_2)\n",
    "    batch_up_2 = tf.keras.layers.Dropout(0.25)(batch_up_2, training=True)\n",
    "\n",
    "\n",
    "    #3\n",
    "    up_3 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(128, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer=init_relu,\n",
    "                                                                          use_bias=False)(batch_up_2), conv_1_1])\n",
    "    batch_up_3 = tf.keras.layers.BatchNormalization()(up_3)\n",
    "    batch_up_3 = tf.keras.layers.Dropout(0.25)(batch_up_3, training=True)\n",
    "\n",
    "\n",
    "    #4\n",
    "    up_4 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(64, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer=init_relu,\n",
    "                                                                          use_bias=False)(batch_up_3), conv_1])\n",
    "    batch_up_4 = tf.keras.layers.BatchNormalization()(up_4)\n",
    "\n",
    "\n",
    "    #Выходной слой\n",
    "    outputs = tf.keras.layers.Conv1DTranspose(NUM_CLASSES, 4, activation='sigmoid', strides=2,\n",
    "                                                   padding='same',\n",
    "                                                   kernel_initializer='glorot_normal')(batch_up_4)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:47:01.125529Z",
     "start_time": "2024-07-31T19:47:00.597528Z"
    }
   },
   "outputs": [],
   "source": [
    "model = unet_multi_model(POINTS_DIM, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:47:02.451170Z",
     "start_time": "2024-07-31T19:47:02.427164Z"
    }
   },
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, alpha=0.1, gamma=2.0):\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))\n",
    "\n",
    "    alpha_factor = y_true * alpha + ((1 - alpha) * (1 - y_true))\n",
    "    modulating_factor = K.pow((1 - p_t), gamma)\n",
    "\n",
    "    # compute the final loss and return\n",
    "    return K.mean(alpha_factor * modulating_factor * bce, axis=-1)\n",
    "\n",
    "def dice_bce_loss(y_pred, y_true):\n",
    "    def dice_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred)\n",
    "        \n",
    "        return 1 - numerator / denominator\n",
    "    total_loss = 0.25 * dice_loss(y_pred, y_true) + tf.keras.losses.binary_crossentropy(y_pred, y_true)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:47:04.318080Z",
     "start_time": "2024-07-31T19:47:04.223999Z"
    }
   },
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "@tf.function\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning side\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:29:09.367495Z",
     "start_time": "2024-07-31T20:29:09.248196Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_v = 1\n",
    "checkpoint_filepath = f'models/ckpt/checkpoint_{ckpt_v}_multi.weights.h5'\n",
    "model.compile(optimizer='adam', loss=dice_bce_loss,\n",
    "                  metrics=['acc', precision, recall, f1_score])\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:29:10.898771Z",
     "start_time": "2024-07-31T20:29:10.887749Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "callbacks_metric1 = 'val_precision'\n",
    "callbacks_metric2 = 'val_loss'\n",
    "callbacks_metric3 = 'val_f1_score'\n",
    "ckpt_v = 1\n",
    "\n",
    "fname = f\"models/ckpt/checkpoint_{ckpt_v}\"+\"-e{epoch:03d}-l{val_loss:.2f}-p{val_precision:.2f}-r{val_recall:.2f}_multi.weights.h5\"  # \" + \"-e{epoch:03d}-l{val_loss:.2f}-p{val_precision:.2f}-r{val_recall:.2f}\n",
    "\n",
    "# checkpoint_filepath = f'models/ckpt/checkpoint_{ckpt_v}_multi-{epoch:03d}-{val_loss:.4f}.weights.h5'\n",
    "callbacks_list = [tf.keras.callbacks.ModelCheckpoint(filepath=fname,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     monitor=callbacks_metric2,\n",
    "                                                     mode='min',\n",
    "                                                     save_best_only=True, verbose=1),\n",
    "                  tf.keras.callbacks.ModelCheckpoint(filepath=fname,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     monitor=callbacks_metric1,\n",
    "                                                     mode='max',\n",
    "                                                     save_best_only=True, verbose=1),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath=fname,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     monitor=callbacks_metric3,\n",
    "                                                     mode='max',\n",
    "                                                     save_best_only=True, verbose=1)]\n",
    "\n",
    "# , tf.keras.callbacks.EarlyStopping(monitor=callbacks_metric, patience=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:44:31.871764Z",
     "start_time": "2024-07-31T20:29:13.030513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - acc: 0.3416 - f1_score: 0.6171 - loss: 0.4624 - precision: 0.7427 - recall: 0.5217\n",
      "Epoch 1: val_loss improved from 0.55087 to 0.48326, saving model to models/ckpt/checkpoint_1-e001-l0.48-p0.72-r0.00_multi.weights.h5\n",
      "\n",
      "Epoch 1: val_precision improved from 0.48764 to 0.72067, saving model to models/ckpt/checkpoint_1-e001-l0.48-p0.72-r0.00_multi.weights.h5\n",
      "\n",
      "Epoch 1: val_f1_score did not improve from 0.33481\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 641ms/step - acc: 0.3438 - f1_score: 0.6168 - loss: 0.4613 - precision: 0.7436 - recall: 0.5212 - val_acc: 0.5489 - val_f1_score: 0.0099 - val_loss: 0.4833 - val_precision: 0.7207 - val_recall: 0.0047\n",
      "Epoch 2/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - acc: 0.5006 - f1_score: 0.6144 - loss: 0.4134 - precision: 0.7950 - recall: 0.5076\n",
      "Epoch 2: val_loss did not improve from 0.48326\n",
      "\n",
      "Epoch 2: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 2: val_f1_score improved from 0.33481 to 0.38337, saving model to models/ckpt/checkpoint_1-e002-l0.52-p0.52-r0.25_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 565ms/step - acc: 0.5035 - f1_score: 0.6147 - loss: 0.4134 - precision: 0.7949 - recall: 0.5069 - val_acc: 0.4789 - val_f1_score: 0.3834 - val_loss: 0.5205 - val_precision: 0.5223 - val_recall: 0.2533\n",
      "Epoch 3/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - acc: 0.7114 - f1_score: 0.6170 - loss: 0.3935 - precision: 0.8097 - recall: 0.4991\n",
      "Epoch 3: val_loss improved from 0.48326 to 0.44224, saving model to models/ckpt/checkpoint_1-e003-l0.44-p0.00-r0.00_multi.weights.h5\n",
      "\n",
      "Epoch 3: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 3: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 561ms/step - acc: 0.7110 - f1_score: 0.6171 - loss: 0.3934 - precision: 0.8094 - recall: 0.5000 - val_acc: 0.3498 - val_f1_score: 0.0000e+00 - val_loss: 0.4422 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - acc: 0.6937 - f1_score: 0.6516 - loss: 0.3767 - precision: 0.8121 - recall: 0.5574\n",
      "Epoch 4: val_loss improved from 0.44224 to 0.43265, saving model to models/ckpt/checkpoint_1-e004-l0.43-p0.00-r0.00_multi.weights.h5\n",
      "\n",
      "Epoch 4: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 4: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 565ms/step - acc: 0.6957 - f1_score: 0.6522 - loss: 0.3767 - precision: 0.8139 - recall: 0.5565 - val_acc: 0.3437 - val_f1_score: 0.0000e+00 - val_loss: 0.4327 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - acc: 0.7626 - f1_score: 0.7056 - loss: 0.3608 - precision: 0.8146 - recall: 0.6106\n",
      "Epoch 5: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 5: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 5: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 560ms/step - acc: 0.7612 - f1_score: 0.7050 - loss: 0.3609 - precision: 0.8157 - recall: 0.6091 - val_acc: 0.4069 - val_f1_score: 0.0695 - val_loss: 0.4436 - val_precision: 0.5842 - val_recall: 0.0303\n",
      "Epoch 6/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - acc: 0.7256 - f1_score: 0.6879 - loss: 0.3551 - precision: 0.8463 - recall: 0.6033\n",
      "Epoch 6: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 6: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 6: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 555ms/step - acc: 0.7255 - f1_score: 0.6890 - loss: 0.3546 - precision: 0.8465 - recall: 0.6045 - val_acc: 0.2093 - val_f1_score: 0.0000e+00 - val_loss: 0.5468 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - acc: 0.7259 - f1_score: 0.7395 - loss: 0.3417 - precision: 0.8228 - recall: 0.6628\n",
      "Epoch 7: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 7: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 7: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 548ms/step - acc: 0.7263 - f1_score: 0.7391 - loss: 0.3413 - precision: 0.8240 - recall: 0.6621 - val_acc: 0.2769 - val_f1_score: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - acc: 0.7352 - f1_score: 0.7806 - loss: 0.3186 - precision: 0.8651 - recall: 0.7242\n",
      "Epoch 8: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 8: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 8: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 549ms/step - acc: 0.7352 - f1_score: 0.7811 - loss: 0.3180 - precision: 0.8650 - recall: 0.7258 - val_acc: 0.2289 - val_f1_score: 0.0000e+00 - val_loss: 0.5418 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - acc: 0.7726 - f1_score: 0.8120 - loss: 0.2934 - precision: 0.8892 - recall: 0.7623\n",
      "Epoch 9: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 9: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 9: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 550ms/step - acc: 0.7713 - f1_score: 0.8125 - loss: 0.2931 - precision: 0.8900 - recall: 0.7629 - val_acc: 0.2618 - val_f1_score: 0.0000e+00 - val_loss: 0.4938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - acc: 0.6867 - f1_score: 0.8795 - loss: 0.2688 - precision: 0.8979 - recall: 0.8545\n",
      "Epoch 10: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 10: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 10: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 546ms/step - acc: 0.6882 - f1_score: 0.8792 - loss: 0.2689 - precision: 0.8980 - recall: 0.8539 - val_acc: 0.5965 - val_f1_score: 0.0000e+00 - val_loss: 0.5483 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - acc: 0.7176 - f1_score: 0.9057 - loss: 0.2468 - precision: 0.9447 - recall: 0.8787\n",
      "Epoch 11: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 11: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 11: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 547ms/step - acc: 0.7173 - f1_score: 0.9060 - loss: 0.2466 - precision: 0.9447 - recall: 0.8794 - val_acc: 0.7800 - val_f1_score: 0.0000e+00 - val_loss: 0.5642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - acc: 0.6918 - f1_score: 0.9355 - loss: 0.2373 - precision: 0.9407 - recall: 0.9106\n",
      "Epoch 12: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 12: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 12: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 554ms/step - acc: 0.6928 - f1_score: 0.9349 - loss: 0.2376 - precision: 0.9405 - recall: 0.9097 - val_acc: 0.7785 - val_f1_score: 0.0099 - val_loss: 0.5715 - val_precision: 0.7154 - val_recall: 0.0034\n",
      "Epoch 13/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - acc: 0.6750 - f1_score: 0.9300 - loss: 0.2326 - precision: 0.9599 - recall: 0.9084\n",
      "Epoch 13: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 13: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 13: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 548ms/step - acc: 0.6746 - f1_score: 0.9302 - loss: 0.2324 - precision: 0.9597 - recall: 0.9092 - val_acc: 0.3256 - val_f1_score: 0.0411 - val_loss: 0.5580 - val_precision: 0.4496 - val_recall: 0.0152\n",
      "Epoch 14/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - acc: 0.7076 - f1_score: 0.9476 - loss: 0.2221 - precision: 0.9638 - recall: 0.9281\n",
      "Epoch 14: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 14: val_precision did not improve from 0.72067\n",
      "\n",
      "Epoch 14: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 550ms/step - acc: 0.7072 - f1_score: 0.9475 - loss: 0.2221 - precision: 0.9636 - recall: 0.9284 - val_acc: 0.3611 - val_f1_score: 5.3711e-04 - val_loss: 0.5736 - val_precision: 0.1351 - val_recall: 1.8195e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.6704 - f1_score: 0.9695 - loss: 0.2108 - precision: 0.9793 - recall: 0.9554\n",
      "Epoch 15: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 15: val_precision improved from 0.72067 to 0.86766, saving model to models/ckpt/checkpoint_1-e015-l0.50-p0.87-r0.04_multi.weights.h5\n",
      "\n",
      "Epoch 15: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 580ms/step - acc: 0.6691 - f1_score: 0.9693 - loss: 0.2108 - precision: 0.9792 - recall: 0.9553 - val_acc: 0.6195 - val_f1_score: 0.0907 - val_loss: 0.4982 - val_precision: 0.8677 - val_recall: 0.0425\n",
      "Epoch 16/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - acc: 0.6137 - f1_score: 0.9642 - loss: 0.2088 - precision: 0.9673 - recall: 0.9690\n",
      "Epoch 16: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 16: val_precision did not improve from 0.86766\n",
      "\n",
      "Epoch 16: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 546ms/step - acc: 0.6146 - f1_score: 0.9644 - loss: 0.2086 - precision: 0.9678 - recall: 0.9688 - val_acc: 0.4150 - val_f1_score: 0.0013 - val_loss: 0.5659 - val_precision: 0.8000 - val_recall: 4.3668e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - acc: 0.6243 - f1_score: 0.9764 - loss: 0.2039 - precision: 0.9811 - recall: 0.9680\n",
      "Epoch 17: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 17: val_precision did not improve from 0.86766\n",
      "\n",
      "Epoch 17: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 546ms/step - acc: 0.6244 - f1_score: 0.9763 - loss: 0.2040 - precision: 0.9811 - recall: 0.9679 - val_acc: 0.7369 - val_f1_score: 0.0812 - val_loss: 0.5313 - val_precision: 0.8022 - val_recall: 0.0350\n",
      "Epoch 18/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - acc: 0.5768 - f1_score: 0.9786 - loss: 0.2016 - precision: 0.9765 - recall: 0.9764\n",
      "Epoch 18: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 18: val_precision improved from 0.86766 to 0.93857, saving model to models/ckpt/checkpoint_1-e018-l0.61-p0.94-r0.02_multi.weights.h5\n",
      "\n",
      "Epoch 18: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 555ms/step - acc: 0.5810 - f1_score: 0.9784 - loss: 0.2017 - precision: 0.9765 - recall: 0.9761 - val_acc: 0.8400 - val_f1_score: 0.0564 - val_loss: 0.6080 - val_precision: 0.9386 - val_recall: 0.0200\n",
      "Epoch 19/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - acc: 0.6839 - f1_score: 0.9784 - loss: 0.2007 - precision: 0.9857 - recall: 0.9727\n",
      "Epoch 19: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 19: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 19: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 555ms/step - acc: 0.6820 - f1_score: 0.9784 - loss: 0.2006 - precision: 0.9856 - recall: 0.9729 - val_acc: 0.5676 - val_f1_score: 0.3793 - val_loss: 0.4756 - val_precision: 0.6055 - val_recall: 0.2382\n",
      "Epoch 20/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - acc: 0.6165 - f1_score: 0.9839 - loss: 0.1962 - precision: 0.9859 - recall: 0.9813\n",
      "Epoch 20: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 20: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 20: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step - acc: 0.6176 - f1_score: 0.9839 - loss: 0.1963 - precision: 0.9859 - recall: 0.9814 - val_acc: 0.7007 - val_f1_score: 0.3292 - val_loss: 0.4995 - val_precision: 0.6645 - val_recall: 0.1821\n",
      "Epoch 21/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - acc: 0.6579 - f1_score: 0.9880 - loss: 0.1965 - precision: 0.9910 - recall: 0.9853\n",
      "Epoch 21: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 21: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 21: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 547ms/step - acc: 0.6545 - f1_score: 0.9880 - loss: 0.1964 - precision: 0.9910 - recall: 0.9854 - val_acc: 0.5711 - val_f1_score: 0.3414 - val_loss: 0.4903 - val_precision: 0.6483 - val_recall: 0.1987\n",
      "Epoch 22/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - acc: 0.4993 - f1_score: 0.9901 - loss: 0.1909 - precision: 0.9918 - recall: 0.9875\n",
      "Epoch 22: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 22: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 22: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 554ms/step - acc: 0.5032 - f1_score: 0.9900 - loss: 0.1911 - precision: 0.9915 - recall: 0.9875 - val_acc: 0.4967 - val_f1_score: 0.3662 - val_loss: 0.5387 - val_precision: 0.6154 - val_recall: 0.2200\n",
      "Epoch 23/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - acc: 0.6079 - f1_score: 0.9819 - loss: 0.2051 - precision: 0.9826 - recall: 0.9705\n",
      "Epoch 23: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 23: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 23: val_f1_score did not improve from 0.38337\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 576ms/step - acc: 0.6059 - f1_score: 0.9816 - loss: 0.2052 - precision: 0.9822 - recall: 0.9701 - val_acc: 0.3233 - val_f1_score: 0.2035 - val_loss: 0.5454 - val_precision: 0.3145 - val_recall: 0.1298\n",
      "Epoch 24/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - acc: 0.5319 - f1_score: 0.9752 - loss: 0.2018 - precision: 0.9805 - recall: 0.9711\n",
      "Epoch 24: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 24: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 24: val_f1_score improved from 0.38337 to 0.38830, saving model to models/ckpt/checkpoint_1-e024-l0.46-p0.49-r0.28_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 556ms/step - acc: 0.5347 - f1_score: 0.9753 - loss: 0.2018 - precision: 0.9805 - recall: 0.9713 - val_acc: 0.4206 - val_f1_score: 0.3883 - val_loss: 0.4557 - val_precision: 0.4869 - val_recall: 0.2822\n",
      "Epoch 25/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - acc: 0.5630 - f1_score: 0.9814 - loss: 0.1980 - precision: 0.9859 - recall: 0.9767\n",
      "Epoch 25: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 25: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 25: val_f1_score did not improve from 0.38830\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 593ms/step - acc: 0.5659 - f1_score: 0.9814 - loss: 0.1981 - precision: 0.9859 - recall: 0.9767 - val_acc: 0.4859 - val_f1_score: 0.3790 - val_loss: 0.4559 - val_precision: 0.6173 - val_recall: 0.2441\n",
      "Epoch 26/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - acc: 0.6169 - f1_score: 0.9860 - loss: 0.1943 - precision: 0.9875 - recall: 0.9859\n",
      "Epoch 26: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 26: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 26: val_f1_score improved from 0.38830 to 0.41235, saving model to models/ckpt/checkpoint_1-e026-l0.48-p0.57-r0.30_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 613ms/step - acc: 0.6142 - f1_score: 0.9861 - loss: 0.1943 - precision: 0.9875 - recall: 0.9860 - val_acc: 0.3084 - val_f1_score: 0.4124 - val_loss: 0.4759 - val_precision: 0.5704 - val_recall: 0.2999\n",
      "Epoch 27/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - acc: 0.5733 - f1_score: 0.9899 - loss: 0.1928 - precision: 0.9919 - recall: 0.9881\n",
      "Epoch 27: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 27: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 27: val_f1_score did not improve from 0.41235\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 573ms/step - acc: 0.5727 - f1_score: 0.9899 - loss: 0.1928 - precision: 0.9919 - recall: 0.9881 - val_acc: 0.3829 - val_f1_score: 0.3578 - val_loss: 0.4952 - val_precision: 0.6299 - val_recall: 0.2154\n",
      "Epoch 28/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - acc: 0.5616 - f1_score: 0.9921 - loss: 0.1916 - precision: 0.9927 - recall: 0.9903\n",
      "Epoch 28: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 28: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 28: val_f1_score improved from 0.41235 to 0.48811, saving model to models/ckpt/checkpoint_1-e028-l0.47-p0.63-r0.34_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5610 - f1_score: 0.9921 - loss: 0.1917 - precision: 0.9927 - recall: 0.9903 - val_acc: 0.5262 - val_f1_score: 0.4881 - val_loss: 0.4680 - val_precision: 0.6286 - val_recall: 0.3371\n",
      "Epoch 29/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - acc: 0.5693 - f1_score: 0.9924 - loss: 0.1919 - precision: 0.9936 - recall: 0.9903\n",
      "Epoch 29: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 29: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 29: val_f1_score improved from 0.48811 to 0.48871, saving model to models/ckpt/checkpoint_1-e029-l0.47-p0.62-r0.35_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5679 - f1_score: 0.9924 - loss: 0.1918 - precision: 0.9936 - recall: 0.9903 - val_acc: 0.4349 - val_f1_score: 0.4887 - val_loss: 0.4740 - val_precision: 0.6191 - val_recall: 0.3542\n",
      "Epoch 30/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - acc: 0.5887 - f1_score: 0.9931 - loss: 0.1894 - precision: 0.9941 - recall: 0.9923\n",
      "Epoch 30: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 30: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 30: val_f1_score improved from 0.48871 to 0.49004, saving model to models/ckpt/checkpoint_1-e030-l0.48-p0.61-r0.35_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 576ms/step - acc: 0.5862 - f1_score: 0.9931 - loss: 0.1895 - precision: 0.9941 - recall: 0.9923 - val_acc: 0.5195 - val_f1_score: 0.4900 - val_loss: 0.4839 - val_precision: 0.6073 - val_recall: 0.3519\n",
      "Epoch 31/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - acc: 0.5654 - f1_score: 0.9922 - loss: 0.1927 - precision: 0.9906 - recall: 0.9931\n",
      "Epoch 31: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 31: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 31: val_f1_score improved from 0.49004 to 0.49879, saving model to models/ckpt/checkpoint_1-e031-l0.48-p0.62-r0.36_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 581ms/step - acc: 0.5641 - f1_score: 0.9922 - loss: 0.1926 - precision: 0.9908 - recall: 0.9930 - val_acc: 0.4807 - val_f1_score: 0.4988 - val_loss: 0.4837 - val_precision: 0.6197 - val_recall: 0.3629\n",
      "Epoch 32/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - acc: 0.5008 - f1_score: 0.9938 - loss: 0.1900 - precision: 0.9925 - recall: 0.9947\n",
      "Epoch 32: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 32: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 32: val_f1_score improved from 0.49879 to 0.51662, saving model to models/ckpt/checkpoint_1-e032-l0.49-p0.59-r0.40_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 575ms/step - acc: 0.5023 - f1_score: 0.9938 - loss: 0.1901 - precision: 0.9926 - recall: 0.9946 - val_acc: 0.4833 - val_f1_score: 0.5166 - val_loss: 0.4877 - val_precision: 0.5866 - val_recall: 0.3978\n",
      "Epoch 33/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - acc: 0.5712 - f1_score: 0.9943 - loss: 0.1904 - precision: 0.9940 - recall: 0.9948\n",
      "Epoch 33: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 33: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 33: val_f1_score did not improve from 0.51662\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 601ms/step - acc: 0.5683 - f1_score: 0.9943 - loss: 0.1903 - precision: 0.9941 - recall: 0.9947 - val_acc: 0.4710 - val_f1_score: 0.4692 - val_loss: 0.5008 - val_precision: 0.5814 - val_recall: 0.3392\n",
      "Epoch 34/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - acc: 0.4665 - f1_score: 0.9946 - loss: 0.1905 - precision: 0.9946 - recall: 0.9943\n",
      "Epoch 34: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 34: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 34: val_f1_score did not improve from 0.51662\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 601ms/step - acc: 0.4702 - f1_score: 0.9946 - loss: 0.1905 - precision: 0.9946 - recall: 0.9942 - val_acc: 0.4855 - val_f1_score: 0.5074 - val_loss: 0.5006 - val_precision: 0.5588 - val_recall: 0.3908\n",
      "Epoch 35/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - acc: 0.5856 - f1_score: 0.9947 - loss: 0.1898 - precision: 0.9951 - recall: 0.9945\n",
      "Epoch 35: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 35: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 35: val_f1_score improved from 0.51662 to 0.51950, saving model to models/ckpt/checkpoint_1-e035-l0.51-p0.55-r0.41_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.5812 - f1_score: 0.9947 - loss: 0.1898 - precision: 0.9951 - recall: 0.9946 - val_acc: 0.4319 - val_f1_score: 0.5195 - val_loss: 0.5075 - val_precision: 0.5545 - val_recall: 0.4120\n",
      "Epoch 36/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - acc: 0.5965 - f1_score: 0.9944 - loss: 0.1919 - precision: 0.9952 - recall: 0.9932\n",
      "Epoch 36: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 36: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 36: val_f1_score did not improve from 0.51950\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 557ms/step - acc: 0.5932 - f1_score: 0.9944 - loss: 0.1917 - precision: 0.9952 - recall: 0.9931 - val_acc: 0.4694 - val_f1_score: 0.5016 - val_loss: 0.5107 - val_precision: 0.5601 - val_recall: 0.3729\n",
      "Epoch 37/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - acc: 0.4784 - f1_score: 0.9942 - loss: 0.1895 - precision: 0.9932 - recall: 0.9953\n",
      "Epoch 37: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 37: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 37: val_f1_score improved from 0.51950 to 0.56046, saving model to models/ckpt/checkpoint_1-e037-l0.61-p0.51-r0.50_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 611ms/step - acc: 0.4804 - f1_score: 0.9942 - loss: 0.1895 - precision: 0.9933 - recall: 0.9952 - val_acc: 0.4459 - val_f1_score: 0.5605 - val_loss: 0.6054 - val_precision: 0.5102 - val_recall: 0.4953\n",
      "Epoch 38/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - acc: 0.5192 - f1_score: 0.9944 - loss: 0.1891 - precision: 0.9946 - recall: 0.9947\n",
      "Epoch 38: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 38: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 38: val_f1_score did not improve from 0.56046\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 583ms/step - acc: 0.5193 - f1_score: 0.9945 - loss: 0.1891 - precision: 0.9946 - recall: 0.9947 - val_acc: 0.4067 - val_f1_score: 0.5186 - val_loss: 0.5388 - val_precision: 0.5645 - val_recall: 0.4088\n",
      "Epoch 39/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - acc: 0.5699 - f1_score: 0.9954 - loss: 0.1913 - precision: 0.9963 - recall: 0.9945\n",
      "Epoch 39: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 39: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 39: val_f1_score did not improve from 0.56046\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.5667 - f1_score: 0.9954 - loss: 0.1911 - precision: 0.9963 - recall: 0.9944 - val_acc: 0.4553 - val_f1_score: 0.4978 - val_loss: 0.5626 - val_precision: 0.4997 - val_recall: 0.4066\n",
      "Epoch 40/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.4326 - f1_score: 0.9959 - loss: 0.1871 - precision: 0.9957 - recall: 0.9957\n",
      "Epoch 40: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 40: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 40: val_f1_score did not improve from 0.56046\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.4371 - f1_score: 0.9959 - loss: 0.1872 - precision: 0.9957 - recall: 0.9957 - val_acc: 0.4945 - val_f1_score: 0.5602 - val_loss: 0.6244 - val_precision: 0.5162 - val_recall: 0.5043\n",
      "Epoch 41/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - acc: 0.5383 - f1_score: 0.9956 - loss: 0.1901 - precision: 0.9967 - recall: 0.9942\n",
      "Epoch 41: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 41: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 41: val_f1_score did not improve from 0.56046\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step - acc: 0.5373 - f1_score: 0.9956 - loss: 0.1901 - precision: 0.9967 - recall: 0.9943 - val_acc: 0.4516 - val_f1_score: 0.5017 - val_loss: 0.5478 - val_precision: 0.5219 - val_recall: 0.3878\n",
      "Epoch 42/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - acc: 0.4589 - f1_score: 0.9965 - loss: 0.1896 - precision: 0.9966 - recall: 0.9959\n",
      "Epoch 42: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 42: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 42: val_f1_score improved from 0.56046 to 0.57971, saving model to models/ckpt/checkpoint_1-e042-l0.67-p0.51-r0.54_multi.weights.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 579ms/step - acc: 0.4610 - f1_score: 0.9965 - loss: 0.1895 - precision: 0.9966 - recall: 0.9958 - val_acc: 0.4299 - val_f1_score: 0.5797 - val_loss: 0.6721 - val_precision: 0.5122 - val_recall: 0.5367\n",
      "Epoch 43/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - acc: 0.5224 - f1_score: 0.9955 - loss: 0.1872 - precision: 0.9959 - recall: 0.9949\n",
      "Epoch 43: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 43: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 43: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 575ms/step - acc: 0.5207 - f1_score: 0.9955 - loss: 0.1873 - precision: 0.9959 - recall: 0.9950 - val_acc: 0.3780 - val_f1_score: 0.5373 - val_loss: 0.6245 - val_precision: 0.5208 - val_recall: 0.4503\n",
      "Epoch 44/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.5066 - f1_score: 0.9935 - loss: 0.1904 - precision: 0.9969 - recall: 0.9901\n",
      "Epoch 44: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 44: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 44: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.5069 - f1_score: 0.9935 - loss: 0.1904 - precision: 0.9968 - recall: 0.9901 - val_acc: 0.5163 - val_f1_score: 0.4296 - val_loss: 0.5595 - val_precision: 0.4547 - val_recall: 0.3269\n",
      "Epoch 45/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.5696 - f1_score: 0.9912 - loss: 0.1929 - precision: 0.9913 - recall: 0.9932\n",
      "Epoch 45: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 45: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 45: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5675 - f1_score: 0.9913 - loss: 0.1928 - precision: 0.9915 - recall: 0.9930 - val_acc: 0.4949 - val_f1_score: 0.3820 - val_loss: 0.6488 - val_precision: 0.4371 - val_recall: 0.2757\n",
      "Epoch 46/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.6121 - f1_score: 0.9675 - loss: 0.2279 - precision: 0.9609 - recall: 0.9488\n",
      "Epoch 46: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 46: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 46: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.6115 - f1_score: 0.9666 - loss: 0.2282 - precision: 0.9607 - recall: 0.9478 - val_acc: 0.7615 - val_f1_score: 0.4536 - val_loss: 1.6454 - val_precision: 0.2782 - val_recall: 0.6181\n",
      "Epoch 47/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - acc: 0.7081 - f1_score: 0.9570 - loss: 0.2127 - precision: 0.9584 - recall: 0.9581\n",
      "Epoch 47: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 47: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 47: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.7095 - f1_score: 0.9571 - loss: 0.2126 - precision: 0.9588 - recall: 0.9581 - val_acc: 0.7490 - val_f1_score: 0.4602 - val_loss: 2.3075 - val_precision: 0.3030 - val_recall: 0.5881\n",
      "Epoch 48/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.7570 - f1_score: 0.9510 - loss: 0.2190 - precision: 0.9573 - recall: 0.9396\n",
      "Epoch 48: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 48: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 48: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.7605 - f1_score: 0.9509 - loss: 0.2189 - precision: 0.9574 - recall: 0.9399 - val_acc: 0.7832 - val_f1_score: 0.4805 - val_loss: 0.5250 - val_precision: 0.4574 - val_recall: 0.3987\n",
      "Epoch 49/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - acc: 0.8484 - f1_score: 0.9754 - loss: 0.2010 - precision: 0.9830 - recall: 0.9716\n",
      "Epoch 49: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 49: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 49: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.8480 - f1_score: 0.9755 - loss: 0.2009 - precision: 0.9830 - recall: 0.9720 - val_acc: 0.6631 - val_f1_score: 0.2065 - val_loss: 0.4869 - val_precision: 0.5936 - val_recall: 0.0993\n",
      "Epoch 50/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.8581 - f1_score: 0.9869 - loss: 0.1953 - precision: 0.9903 - recall: 0.9844\n",
      "Epoch 50: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 50: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 50: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.8562 - f1_score: 0.9870 - loss: 0.1952 - precision: 0.9904 - recall: 0.9844 - val_acc: 0.6930 - val_f1_score: 0.2220 - val_loss: 0.5070 - val_precision: 0.5896 - val_recall: 0.1112\n",
      "Epoch 51/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - acc: 0.7666 - f1_score: 0.9924 - loss: 0.1911 - precision: 0.9928 - recall: 0.9924\n",
      "Epoch 51: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 51: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 51: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step - acc: 0.7672 - f1_score: 0.9925 - loss: 0.1911 - precision: 0.9928 - recall: 0.9924 - val_acc: 0.6209 - val_f1_score: 0.3902 - val_loss: 0.4824 - val_precision: 0.6010 - val_recall: 0.2343\n",
      "Epoch 52/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - acc: 0.8170 - f1_score: 0.9934 - loss: 0.1918 - precision: 0.9951 - recall: 0.9924\n",
      "Epoch 52: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 52: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 52: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 566ms/step - acc: 0.8157 - f1_score: 0.9935 - loss: 0.1917 - precision: 0.9951 - recall: 0.9924 - val_acc: 0.7100 - val_f1_score: 0.4402 - val_loss: 0.4781 - val_precision: 0.6074 - val_recall: 0.2959\n",
      "Epoch 53/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - acc: 0.7802 - f1_score: 0.9941 - loss: 0.1911 - precision: 0.9949 - recall: 0.9937\n",
      "Epoch 53: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 53: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 53: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 573ms/step - acc: 0.7779 - f1_score: 0.9942 - loss: 0.1910 - precision: 0.9949 - recall: 0.9937 - val_acc: 0.5689 - val_f1_score: 0.3827 - val_loss: 0.5141 - val_precision: 0.5177 - val_recall: 0.2364\n",
      "Epoch 54/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.7163 - f1_score: 0.9949 - loss: 0.1885 - precision: 0.9954 - recall: 0.9949\n",
      "Epoch 54: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 54: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 54: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.7170 - f1_score: 0.9949 - loss: 0.1886 - precision: 0.9954 - recall: 0.9949 - val_acc: 0.6952 - val_f1_score: 0.4671 - val_loss: 0.4848 - val_precision: 0.5580 - val_recall: 0.3366\n",
      "Epoch 55/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.6818 - f1_score: 0.9955 - loss: 0.1881 - precision: 0.9968 - recall: 0.9940\n",
      "Epoch 55: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 55: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 55: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.6843 - f1_score: 0.9955 - loss: 0.1882 - precision: 0.9968 - recall: 0.9941 - val_acc: 0.6236 - val_f1_score: 0.4629 - val_loss: 0.4941 - val_precision: 0.5694 - val_recall: 0.3196\n",
      "Epoch 56/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - acc: 0.7063 - f1_score: 0.9963 - loss: 0.1896 - precision: 0.9966 - recall: 0.9960\n",
      "Epoch 56: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 56: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 56: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step - acc: 0.7059 - f1_score: 0.9963 - loss: 0.1895 - precision: 0.9966 - recall: 0.9960 - val_acc: 0.6638 - val_f1_score: 0.4493 - val_loss: 0.5199 - val_precision: 0.5570 - val_recall: 0.3089\n",
      "Epoch 57/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.7092 - f1_score: 0.9965 - loss: 0.1886 - precision: 0.9970 - recall: 0.9960\n",
      "Epoch 57: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 57: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 57: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.7083 - f1_score: 0.9965 - loss: 0.1886 - precision: 0.9970 - recall: 0.9960 - val_acc: 0.6457 - val_f1_score: 0.4638 - val_loss: 0.5139 - val_precision: 0.5517 - val_recall: 0.3293\n",
      "Epoch 58/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - acc: 0.6719 - f1_score: 0.9968 - loss: 0.1871 - precision: 0.9971 - recall: 0.9964\n",
      "Epoch 58: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 58: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 58: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step - acc: 0.6718 - f1_score: 0.9968 - loss: 0.1872 - precision: 0.9971 - recall: 0.9964 - val_acc: 0.6333 - val_f1_score: 0.4568 - val_loss: 0.5033 - val_precision: 0.5661 - val_recall: 0.3176\n",
      "Epoch 59/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - acc: 0.6595 - f1_score: 0.9963 - loss: 0.1856 - precision: 0.9975 - recall: 0.9953\n",
      "Epoch 59: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 59: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 59: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 566ms/step - acc: 0.6609 - f1_score: 0.9963 - loss: 0.1858 - precision: 0.9975 - recall: 0.9953 - val_acc: 0.6090 - val_f1_score: 0.5017 - val_loss: 0.5410 - val_precision: 0.5364 - val_recall: 0.3997\n",
      "Epoch 60/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.6493 - f1_score: 0.9972 - loss: 0.1874 - precision: 0.9978 - recall: 0.9965\n",
      "Epoch 60: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 60: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 60: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.6493 - f1_score: 0.9972 - loss: 0.1875 - precision: 0.9978 - recall: 0.9966 - val_acc: 0.6071 - val_f1_score: 0.4877 - val_loss: 0.5285 - val_precision: 0.5349 - val_recall: 0.3646\n",
      "Epoch 61/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.6757 - f1_score: 0.9973 - loss: 0.1872 - precision: 0.9981 - recall: 0.9963\n",
      "Epoch 61: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 61: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 61: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.6740 - f1_score: 0.9973 - loss: 0.1872 - precision: 0.9980 - recall: 0.9963 - val_acc: 0.5818 - val_f1_score: 0.4976 - val_loss: 0.5360 - val_precision: 0.5202 - val_recall: 0.3873\n",
      "Epoch 62/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - acc: 0.6157 - f1_score: 0.9970 - loss: 0.1888 - precision: 0.9972 - recall: 0.9965\n",
      "Epoch 62: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 62: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 62: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 573ms/step - acc: 0.6157 - f1_score: 0.9970 - loss: 0.1888 - precision: 0.9972 - recall: 0.9965 - val_acc: 0.5735 - val_f1_score: 0.5132 - val_loss: 0.5505 - val_precision: 0.5410 - val_recall: 0.4056\n",
      "Epoch 63/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.6235 - f1_score: 0.9974 - loss: 0.1880 - precision: 0.9982 - recall: 0.9966\n",
      "Epoch 63: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 63: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 63: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.6236 - f1_score: 0.9974 - loss: 0.1880 - precision: 0.9982 - recall: 0.9966 - val_acc: 0.5946 - val_f1_score: 0.4978 - val_loss: 0.5607 - val_precision: 0.5281 - val_recall: 0.3918\n",
      "Epoch 64/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - acc: 0.5238 - f1_score: 0.9964 - loss: 0.1867 - precision: 0.9973 - recall: 0.9962\n",
      "Epoch 64: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 64: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 64: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.5302 - f1_score: 0.9964 - loss: 0.1868 - precision: 0.9973 - recall: 0.9963 - val_acc: 0.5647 - val_f1_score: 0.4884 - val_loss: 0.5521 - val_precision: 0.5134 - val_recall: 0.3857\n",
      "Epoch 65/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.6217 - f1_score: 0.9974 - loss: 0.1880 - precision: 0.9980 - recall: 0.9969\n",
      "Epoch 65: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 65: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 65: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.6217 - f1_score: 0.9974 - loss: 0.1880 - precision: 0.9980 - recall: 0.9969 - val_acc: 0.5931 - val_f1_score: 0.5200 - val_loss: 0.5548 - val_precision: 0.5226 - val_recall: 0.4257\n",
      "Epoch 66/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.6052 - f1_score: 0.9979 - loss: 0.1869 - precision: 0.9979 - recall: 0.9978\n",
      "Epoch 66: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 66: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 66: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.6052 - f1_score: 0.9979 - loss: 0.1870 - precision: 0.9979 - recall: 0.9978 - val_acc: 0.5277 - val_f1_score: 0.4710 - val_loss: 0.5636 - val_precision: 0.5205 - val_recall: 0.3559\n",
      "Epoch 67/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.5495 - f1_score: 0.9979 - loss: 0.1860 - precision: 0.9984 - recall: 0.9973\n",
      "Epoch 67: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 67: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 67: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5528 - f1_score: 0.9979 - loss: 0.1861 - precision: 0.9983 - recall: 0.9974 - val_acc: 0.5648 - val_f1_score: 0.5294 - val_loss: 0.5816 - val_precision: 0.5268 - val_recall: 0.4444\n",
      "Epoch 68/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - acc: 0.5541 - f1_score: 0.9979 - loss: 0.1856 - precision: 0.9985 - recall: 0.9972\n",
      "Epoch 68: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 68: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 68: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5570 - f1_score: 0.9979 - loss: 0.1858 - precision: 0.9984 - recall: 0.9972 - val_acc: 0.5521 - val_f1_score: 0.5182 - val_loss: 0.5778 - val_precision: 0.5225 - val_recall: 0.4300\n",
      "Epoch 69/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - acc: 0.5922 - f1_score: 0.9980 - loss: 0.1887 - precision: 0.9986 - recall: 0.9973\n",
      "Epoch 69: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 69: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 69: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5921 - f1_score: 0.9980 - loss: 0.1886 - precision: 0.9986 - recall: 0.9973 - val_acc: 0.5492 - val_f1_score: 0.4831 - val_loss: 0.5940 - val_precision: 0.5095 - val_recall: 0.3793\n",
      "Epoch 70/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.6097 - f1_score: 0.9979 - loss: 0.1868 - precision: 0.9982 - recall: 0.9978\n",
      "Epoch 70: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 70: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 70: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572ms/step - acc: 0.6085 - f1_score: 0.9979 - loss: 0.1869 - precision: 0.9982 - recall: 0.9978 - val_acc: 0.5346 - val_f1_score: 0.5641 - val_loss: 0.6227 - val_precision: 0.5310 - val_recall: 0.4968\n",
      "Epoch 71/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.5834 - f1_score: 0.9980 - loss: 0.1871 - precision: 0.9986 - recall: 0.9974\n",
      "Epoch 71: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 71: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 71: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572ms/step - acc: 0.5831 - f1_score: 0.9980 - loss: 0.1871 - precision: 0.9986 - recall: 0.9974 - val_acc: 0.5447 - val_f1_score: 0.5215 - val_loss: 0.6068 - val_precision: 0.5248 - val_recall: 0.4386\n",
      "Epoch 72/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.5657 - f1_score: 0.9980 - loss: 0.1866 - precision: 0.9980 - recall: 0.9982\n",
      "Epoch 72: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 72: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 72: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.5674 - f1_score: 0.9980 - loss: 0.1866 - precision: 0.9980 - recall: 0.9981 - val_acc: 0.5315 - val_f1_score: 0.5412 - val_loss: 0.5821 - val_precision: 0.5372 - val_recall: 0.4628\n",
      "Epoch 73/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.5919 - f1_score: 0.9984 - loss: 0.1887 - precision: 0.9986 - recall: 0.9981\n",
      "Epoch 73: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 73: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 73: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5911 - f1_score: 0.9984 - loss: 0.1886 - precision: 0.9986 - recall: 0.9981 - val_acc: 0.5234 - val_f1_score: 0.5206 - val_loss: 0.5964 - val_precision: 0.5277 - val_recall: 0.4316\n",
      "Epoch 74/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.5292 - f1_score: 0.9985 - loss: 0.1852 - precision: 0.9986 - recall: 0.9984\n",
      "Epoch 74: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 74: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 74: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 571ms/step - acc: 0.5315 - f1_score: 0.9985 - loss: 0.1853 - precision: 0.9986 - recall: 0.9984 - val_acc: 0.4713 - val_f1_score: 0.5142 - val_loss: 0.5895 - val_precision: 0.5224 - val_recall: 0.4124\n",
      "Epoch 75/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.5737 - f1_score: 0.9987 - loss: 0.1874 - precision: 0.9991 - recall: 0.9982\n",
      "Epoch 75: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 75: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 75: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.5729 - f1_score: 0.9987 - loss: 0.1873 - precision: 0.9991 - recall: 0.9982 - val_acc: 0.5107 - val_f1_score: 0.5317 - val_loss: 0.6468 - val_precision: 0.5184 - val_recall: 0.4411\n",
      "Epoch 76/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - acc: 0.5355 - f1_score: 0.9986 - loss: 0.1860 - precision: 0.9986 - recall: 0.9986\n",
      "Epoch 76: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 76: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 76: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572ms/step - acc: 0.5373 - f1_score: 0.9986 - loss: 0.1861 - precision: 0.9986 - recall: 0.9986 - val_acc: 0.5282 - val_f1_score: 0.5088 - val_loss: 0.5980 - val_precision: 0.5215 - val_recall: 0.4135\n",
      "Epoch 77/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.6065 - f1_score: 0.9983 - loss: 0.1881 - precision: 0.9986 - recall: 0.9982\n",
      "Epoch 77: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 77: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 77: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - acc: 0.6039 - f1_score: 0.9983 - loss: 0.1881 - precision: 0.9986 - recall: 0.9982 - val_acc: 0.5089 - val_f1_score: 0.5412 - val_loss: 0.6651 - val_precision: 0.5113 - val_recall: 0.4665\n",
      "Epoch 78/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.5622 - f1_score: 0.9987 - loss: 0.1867 - precision: 0.9988 - recall: 0.9986\n",
      "Epoch 78: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 78: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 78: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572ms/step - acc: 0.5620 - f1_score: 0.9987 - loss: 0.1867 - precision: 0.9988 - recall: 0.9986 - val_acc: 0.4903 - val_f1_score: 0.4784 - val_loss: 0.5798 - val_precision: 0.5166 - val_recall: 0.3696\n",
      "Epoch 79/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - acc: 0.5839 - f1_score: 0.9987 - loss: 0.1871 - precision: 0.9990 - recall: 0.9983\n",
      "Epoch 79: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 79: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 79: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - acc: 0.5826 - f1_score: 0.9987 - loss: 0.1871 - precision: 0.9990 - recall: 0.9983 - val_acc: 0.5151 - val_f1_score: 0.5456 - val_loss: 0.6213 - val_precision: 0.5319 - val_recall: 0.4651\n",
      "Epoch 80/80\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - acc: 0.5647 - f1_score: 0.9989 - loss: 0.1870 - precision: 0.9988 - recall: 0.9987\n",
      "Epoch 80: val_loss did not improve from 0.43265\n",
      "\n",
      "Epoch 80: val_precision did not improve from 0.93857\n",
      "\n",
      "Epoch 80: val_f1_score did not improve from 0.57971\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572ms/step - acc: 0.5651 - f1_score: 0.9989 - loss: 0.1870 - precision: 0.9988 - recall: 0.9987 - val_acc: 0.4867 - val_f1_score: 0.5114 - val_loss: 0.6190 - val_precision: 0.5225 - val_recall: 0.4197\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=dice_bce_loss, metrics=['acc', precision, recall, f1_score])  # remove to train from ckpt\n",
    "history = model.fit(X_train, y_train, epochs=NUM_EPOCHS,callbacks=callbacks_list, validation_split=0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## History checking\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Saving NN side\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_version = 1\n",
    "model.save(f\"models/unet_v{neu_version}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:46:59.130259Z",
     "start_time": "2024-07-31T19:46:59.088176Z"
    }
   },
   "outputs": [],
   "source": [
    "def unet_model(POINTS_DIM):\n",
    "\n",
    "    #Входной слой\n",
    "    inputs = tf.keras.layers.Input(shape=(POINTS_DIM, 1,))\n",
    "    conv_1 = tf.keras.layers.Conv1D(64, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(),\n",
    "                                    strides=2, padding='same', \n",
    "                                    kernel_initializer='glorot_normal',\n",
    "                                    use_bias=False)(inputs)\n",
    "    #Сворачиваем\n",
    "    conv_1_1 = tf.keras.layers.Conv1D(128, 4, \n",
    "                                      activation=tf.keras.layers.LeakyReLU(), \n",
    "                                      strides=2,\n",
    "                                      padding='same', \n",
    "                                      kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(conv_1)\n",
    "    batch_norm_1 = tf.keras.layers.BatchNormalization()(conv_1_1)\n",
    "\n",
    "    #2\n",
    "    conv_2 = tf.keras.layers.Conv1D(256, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer='glorot_normal',\n",
    "                                    use_bias=False)(batch_norm_1)\n",
    "    batch_norm_2 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "\n",
    "    #3\n",
    "    conv_3 = tf.keras.layers.Conv1D(512, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer='glorot_normal',\n",
    "                                    use_bias=False)(batch_norm_2)\n",
    "    batch_norm_3 = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "\n",
    "    #4\n",
    "    conv_4 = tf.keras.layers.Conv1D(512, 4, \n",
    "                                    activation=tf.keras.layers.LeakyReLU(), \n",
    "                                    strides=2,\n",
    "                                    padding='same', \n",
    "                                    kernel_initializer='glorot_normal',\n",
    "                                    use_bias=False)(batch_norm_3)\n",
    "    batch_norm_4 = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "\n",
    "    #Разворачиваем\n",
    "    #1\n",
    "    up_1 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(512, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(conv_4), conv_3])\n",
    "    batch_up_1 = tf.keras.layers.BatchNormalization()(up_1)\n",
    "\n",
    "    #Добавим Dropout от переобучения\n",
    "    batch_up_1 = tf.keras.layers.Dropout(0.25)(batch_up_1, training=True)\n",
    "\n",
    "    #2\n",
    "    up_2 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(256, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_1), conv_2])\n",
    "    batch_up_2 = tf.keras.layers.BatchNormalization()(up_2)\n",
    "    batch_up_2 = tf.keras.layers.Dropout(0.25)(batch_up_2, training=True)\n",
    "\n",
    "\n",
    "    #3\n",
    "    up_3 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(128, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_2), conv_1_1])\n",
    "    batch_up_3 = tf.keras.layers.BatchNormalization()(up_3)\n",
    "    batch_up_3 = tf.keras.layers.Dropout(0.25)(batch_up_3, training=True)\n",
    "\n",
    "\n",
    "    #4\n",
    "    up_4 = tf.keras.layers.Concatenate()([tf.keras.layers.Conv1DTranspose(64, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_3), conv_1])\n",
    "    batch_up_4 = tf.keras.layers.BatchNormalization()(up_4)\n",
    "\n",
    "\n",
    "    #Выходной слой\n",
    "    max_pool = tf.keras.layers.MaxPooling1D(pool_size=2)(batch_up_4)\n",
    "    flat = tf.keras.layers.Flatten()(max_pool)\n",
    "    flat = tf.keras.layers.Dropout(0.2)(flat, training=True)\n",
    "    outputs = tf.keras.layers.Dense(POINTS_DIM, activation=\"sigmoid\")(flat)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
